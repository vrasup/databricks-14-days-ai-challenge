{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c77c364-51fb-43a4-b3c2-4f3ba5658bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 1: Load Features & Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "765a67fa-628e-462e-970f-1f3bb6652a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['price_log', 'hour', 'day_of_week', 'is_weekend', 'time_since_first_event']\nNumber of rows: 109010\nLabel distribution:\n label\n0    107340\n1      1670\nName: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1: Load the gold table\n",
    "ml_features = spark.table(\"gold.ml_features\")\n",
    "\n",
    "#Step 1.2: Sample the dataset to avoid kernel crash (0.1% of ~109M rows)\n",
    "df_sampled = ml_features.sample(fraction=0.001,seed=42)\n",
    "\n",
    "# Step 1.3: Drop the nulls\n",
    "df_sampled = df_sampled.dropna()\n",
    "\n",
    "# Step 1.4: Convert to Pandas\n",
    "df_ml = df_sampled.toPandas()\n",
    "\n",
    "# Step 1.5: Separate features and label\n",
    "X = df_ml.drop('label', axis=1)\n",
    "y = df_ml['label']\n",
    "\n",
    "# Step 1.5: verify\n",
    "print(\"Feature Columns:\", X.columns.tolist())\n",
    "print(\"Number of rows:\", X.shape[0])\n",
    "print(\"Label distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0834af88-2ee2-4b0b-918a-140f573298b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 2: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1789b12b-3911-4fb2-97eb-643e5dd4d630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows: 87208\nTest rows: 21802\n\nTrain label distribution: {0: 85872, 1: 1336}\nTest label distribution: {0: 21468, 1: 334}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Print row counts\n",
    "print(\"Training rows:\", X_train.shape[0])\n",
    "print(\"Test rows:\", X_test.shape[0])\n",
    "\n",
    "# Print label distribution safely\n",
    "print(\"\\nTrain label distribution:\", y_train.value_counts().to_dict())\n",
    "print(\"Test label distribution:\", y_test.value_counts().to_dict())\n",
    "\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff844fa-1c90-4853-8c63-d0b04ebc1960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 3: MLflow Experiment -Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b83650e-a1cf-466a-a186-18ec04f4c2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n [[11778  9690]\n [  149   185]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:02:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished. Accuracy: 0.5487, ROC AUC: 0.5769\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,confusion_matrix\n",
    "\n",
    "#Start MLflow experiment\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistic_regression_v1\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    #Train the model\n",
    "    model = LogisticRegression(max_iter=200, class_weight=\"balanced\") #class_weight balances for imbalance\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "\n",
    "    #Optional: log confusion matrix as artifact\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    #Log the model\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Run finished. Accuracy: {acc:.4f}, ROC AUC: {roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f69039df-1558-4f34-9936-59cec9042b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- #### Step 4: Random Forest with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba0889b-10dd-423a-aff8-19be9705d2e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 8"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n [[16521  4947]\n [  202   132]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:02:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest run finished. Accuracy: 0.7638, ROC-AUC: 0.6323, Precision: 0.0260, Recall: 0.3952, F1: 0.0488\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "#Start MLflow experiment\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest_v1\"):\n",
    "    #Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    mlflow.log_param(\"n_estimators\", 150)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    #Train the model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=10,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict on test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    #log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    #Optional: log confusion matrix as artifact\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    #Log the model\n",
    "    mlflow.sklearn.log_model(rf, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Random Forest run finished. Accuracy: {acc:.4f}, ROC-AUC: {roc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3643c1dc-540e-4a7f-8b53-8522951c43b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 5: Gradient Boosting (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd50c4f0-2fe7-438b-b204-0a05ee65fb54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n [[15359  6109]\n [  177   157]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:03:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Weighted (threshold=0.5) run finished. Accuracy: 0.7117, ROC-AUC: 0.6384, Precision: 0.0251, Recall: 0.4701, F1: 0.0476\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# End any active MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"gradient_boosting_weighted\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"GradientBoosting\")\n",
    "    mlflow.log_param(\"n_estimators\", 300)\n",
    "    mlflow.log_param(\"max_depth\", 5)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"threshold\", 0.5)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    # Compute sample weights for class imbalance\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "    # Train model with sample weights\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    )\n",
    "    gb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Apply threshold for minority class\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Optional: print confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(gb, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Gradient Boosting Weighted (threshold={threshold}) run finished. Accuracy: {acc:.4f}, ROC-AUC: {roc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0dad698-1f99-4149-8464-ad828687e7bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 6: Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0371c6a7-0185-4063-8ac4-59bb62321825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n [[ 2625 18843]\n [   16   318]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:03:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Weighted (threshold=0.3) run finished. Accuracy: 0.1350, ROC-AUC: 0.5935, Precision: 0.0166, Recall: 0.9521, F1: 0.0326\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# End any active MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"extra_trees_weighted\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"ExtraTrees\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"threshold\", 0.3)\n",
    "    \n",
    "    # Compute sample weights for class imbalance\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "    \n",
    "    # Train model\n",
    "    et = ExtraTreesClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    et.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_proba = et.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = 0.3\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(et, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Extra Trees Weighted (threshold={threshold}) run finished. Accuracy: {acc:.4f}, ROC-AUC: {roc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b0f448-4d63-43ab-a596-9c1fa9df48a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 7: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b4b9d8-5368-43ee-90f7-96da87e094fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n [[ 1655 19813]\n [    3   331]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:03:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Weighted (threshold=0.4) run finished. Accuracy: 0.0911, ROC-AUC: 0.5342, Precision: 0.0164, Recall: 0.9910, F1: 0.0323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# End any active MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=\"adaboost_weighted\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"AdaBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 150)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"threshold\", 0.4)\n",
    "    \n",
    "    # Compute sample weights for class imbalance\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "    \n",
    "    # Train model\n",
    "    ab = AdaBoostClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    ab.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_proba = ab.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Apply threshold\n",
    "    threshold = 0.4\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(ab, artifact_path=\"model\")\n",
    "\n",
    "print(f\"AdaBoost Weighted (threshold={threshold}) run finished. Accuracy: {acc:.4f}, ROC-AUC: {roc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d45a9f04-99ad-4d50-afa2-e0bb586f221b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 8: Train models & find best per-model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e8879d3-a363-4fe1-91e4-6e40505a9f80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: RandomForest\nBest RandomForest: ROC-AUC=0.6323, F1=0.0513, Threshold=0.6\nRunning model: GradientBoosting\nBest GradientBoosting: ROC-AUC=0.6416, F1=0.0560, Threshold=0.6\nRunning model: ExtraTrees\nBest ExtraTrees: ROC-AUC=0.5956, F1=0.0405, Threshold=0.6\nRunning model: AdaBoost\nBest AdaBoost: ROC-AUC=0.5341, F1=0.0302, Threshold=0.1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import numpy as np\n",
    "\n",
    "# End any active MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    \"RandomForest\": {\"model\": RandomForestClassifier, \"params\": {\"n_estimators\": [100,150], \"max_depth\": [5,10]}},\n",
    "    \"GradientBoosting\": {\"model\": GradientBoostingClassifier, \"params\": {\"n_estimators\": [200,300], \"max_depth\": [3,5], \"learning_rate\":[0.05,0.1]}},\n",
    "    \"ExtraTrees\": {\"model\": ExtraTreesClassifier, \"params\": {\"n_estimators\": [100,150], \"max_depth\": [5,10]}},\n",
    "    \"AdaBoost\": {\"model\": AdaBoostClassifier, \"params\": {\"n_estimators\": [100,150], \"learning_rate\":[0.05,0.1]}}\n",
    "}\n",
    "\n",
    "# Thresholds to try for minority class\n",
    "thresholds = [0.1, 0.3, 0.5, 0.6]\n",
    "\n",
    "# Store best results per model\n",
    "best_results = {}\n",
    "\n",
    "# Loop over models\n",
    "for model_name, m_info in models.items():\n",
    "    print(f\"Running model: {model_name}\")\n",
    "    ModelClass = m_info[\"model\"]\n",
    "    param_grid = m_info[\"params\"]\n",
    "    \n",
    "    best_f1 = -1\n",
    "    best_metrics = None\n",
    "    \n",
    "    # Grid search over parameters\n",
    "    import itertools\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for param_set in itertools.product(*values):\n",
    "        params = dict(zip(keys, param_set))\n",
    "        \n",
    "        # Compute sample weights for class imbalance if supported\n",
    "        sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train) if model_name != \"AdaBoost\" else None\n",
    "        \n",
    "        # Train model\n",
    "        model = ModelClass(**params, random_state=42)\n",
    "        if sample_weights is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Try all thresholds\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_proba > threshold).astype(int)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            roc = roc_auc_score(y_test, y_proba)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Save if F1 improves\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_metrics = {\n",
    "                    \"model_name\": model_name,\n",
    "                    \"params\": params,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"accuracy\": acc,\n",
    "                    \"roc_auc\": roc,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1\": f1,\n",
    "                    \"confusion_matrix\": cm\n",
    "                }\n",
    "    \n",
    "    best_results[model_name] = best_metrics\n",
    "    print(f\"Best {model_name}: ROC-AUC={best_metrics['roc_auc']:.4f}, F1={best_metrics['f1']:.4f}, Threshold={best_metrics['threshold']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ff6accb-0a15-43ad-baad-d3dd64ed9917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 9: Overall Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176a3237-336d-4a08-9255-e958f0844025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nOVERALL BEST MODEL\nModel: GradientBoosting\nParams: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1}\nThreshold: 0.6\nAccuracy: 0.8547\nROC-AUC: 0.6416\nPrecision: 0.0311\nRecall: 0.2814\nF1: 0.0560\nConfusion Matrix:\n[[18540  2928]\n [  240    94]]\n================================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/20 00:08:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall best model logged to MLflow successfully!\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Find overall best model by F1 score\n",
    "overall_best = max(best_results.values(), key=lambda x: x['f1'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OVERALL BEST MODEL\")\n",
    "print(f\"Model: {overall_best['model_name']}\")\n",
    "print(f\"Params: {overall_best['params']}\")\n",
    "print(f\"Threshold: {overall_best['threshold']}\")\n",
    "print(f\"Accuracy: {overall_best['accuracy']:.4f}\")\n",
    "print(f\"ROC-AUC: {overall_best['roc_auc']:.4f}\")\n",
    "print(f\"Precision: {overall_best['precision']:.4f}\")\n",
    "print(f\"Recall: {overall_best['recall']:.4f}\")\n",
    "print(f\"F1: {overall_best['f1']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(overall_best['confusion_matrix'])\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Optional: log overall best model to MLflow\n",
    "mlflow.end_run()\n",
    "mlflow.set_experiment(\"/Shared/day12_purchase_prediction\")\n",
    "with mlflow.start_run(run_name=\"overall_best_model\"):\n",
    "    mlflow.log_param(\"model_name\", overall_best['model_name'])\n",
    "    mlflow.log_params(overall_best['params'])\n",
    "    mlflow.log_param(\"threshold\", overall_best['threshold'])\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", overall_best['accuracy'])\n",
    "    mlflow.log_metric(\"roc_auc\", overall_best['roc_auc'])\n",
    "    mlflow.log_metric(\"precision\", overall_best['precision'])\n",
    "    mlflow.log_metric(\"recall\", overall_best['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", overall_best['f1'])\n",
    "    \n",
    "    # Log the model artifact\n",
    "    # Re-train the model with best params and sample weights\n",
    "    ModelClass = {\n",
    "        \"RandomForest\": RandomForestClassifier,\n",
    "        \"GradientBoosting\": GradientBoostingClassifier,\n",
    "        \"ExtraTrees\": ExtraTreesClassifier,\n",
    "        \"AdaBoost\": AdaBoostClassifier\n",
    "    }[overall_best['model_name']]\n",
    "    \n",
    "    model_params = overall_best['params']\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train) if overall_best['model_name'] != \"AdaBoost\" else None\n",
    "    model = ModelClass(**model_params, random_state=42)\n",
    "    if sample_weights is not None:\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "print(\"Overall best model logged to MLflow successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 12_Task_Vidhya Rasu",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}